{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9be4b7c-5f6a-4040-a760-29c9db9a6a34",
   "metadata": {},
   "source": [
    "<h1><center>CNN Classifier</center></h1>\n",
    "\n",
    "<h3><center>Presented by : Altaf Ur Rahman</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2a9999-f8cb-4e50-ab5f-b0619fb30595",
   "metadata": {},
   "source": [
    "***\n",
    "*This notebook presents basic CNN Classifier using PyTorch. Model Architecture consist of 3 convolutional layers, batch normalization and pooling layers while relu non linearity is used. Intel Dataset consist of 6 distant classes with 14000 training and 3000 images is fed to the model for training and prediction.*\n",
    "***\n",
    "Following are the sections of this notebook, \n",
    "\n",
    "**Step 01:** *Importing librararies & setting Paths*\\\n",
    "**Step 02:** *Data Loading and Pre Processing*\\\n",
    "**Step 03**: *Network Architecture* \\\n",
    "**Step 04:** *Defining Loss and Optimizer*\\\n",
    "**Step 05:** *Model Training*\\\n",
    "**Step 06:** *Model Testing*\\\n",
    "**Step 07:** *Results Evaluation and Visualization*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bddb504-29a5-494a-96ff-10a3f6410d61",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<center> Step 01: Importing librararies & setting Paths</center>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a03faa2-e5b1-427b-aa6b-66ac8e06cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "import pathlib\n",
    "import cv2\n",
    "\n",
    "# libraries for visualization and evaluation matrices\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "954b190b-83e9-4f27-9287-d363c4bbe03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for device\n",
    "#device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda')\n",
    "\n",
    "#Path for training and testing directory\n",
    "train_root='./data1/Intel_dataset/seg_train/seg_train'\n",
    "test_root= './data1/Intel_dataset/seg_test/seg_test'\n",
    "\n",
    "# defining some hyper parameters of the network\n",
    "batch_size = 32\n",
    "num_epochs= 200\n",
    "num_workers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc264226-c431-4516-9f8c-9d5644a1a178",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<center>Step 02: Data Loading and Pre Processing </center>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "294ed0e0-9057-4148-8131-a7292e7b1ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([ transforms.Resize((150,150)),                       # Resize the image \n",
    "                                transforms.ToTensor(),                                     # Convert to Tensors\n",
    "                                transforms.RandomHorizontalFlip(),                         # Data Augmentations\n",
    "                                transforms.RandomRotation(degrees=15),   \n",
    "                                transforms.RandomVerticalFlip(p=0.5),      \n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])   #Mean Normalization (x-mean/STD) = [-1,1]\n",
    "test_transform = transforms.Compose( [transforms.Resize((150,150)),                        # Resize the image \n",
    "                                transforms.ToTensor(),                                     # Convert to Tensors\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])   #Mean Normalization (x-mean/STD) = [-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "641a14b2-9476-4204-ae0e-6d8bba1b6431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images are:     10526\n",
      "Validation images are:   3508\n",
      "Testing images are:      3000 \n",
      "\n",
      "Classes are:  ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n"
     ]
    }
   ],
   "source": [
    "# Lets define our datasets and dataloaders\n",
    "\n",
    "#####################################[[[[[[[[[    Datasets    ]]]]]]]]]]]#############################################\n",
    "\n",
    "# defining training and validation datasets [Note: This is inefficient way of loading the data: Efficient way: design custom dataset/dataloader]\n",
    "train_set0 = datasets.ImageFolder(train_root,transform=train_transform)\n",
    "val_set0 = datasets.ImageFolder(train_root,transform=test_transform)\n",
    "test_set = datasets.ImageFolder(test_root ,transform=test_transform)\n",
    "\n",
    "# Divide training set into validation set (0.25) and training set(0.75)\n",
    "train_set, Sparse0 = torch.utils.data.random_split(train_set0, [int(len(train_set0) * 0.75)+1, int(len(train_set0) * 0.25)])\n",
    "Sparse1, val_set = torch.utils.data.random_split(val_set0, [int(len(val_set0) * 0.75)+1, int(len(val_set0) * 0.25)])\n",
    "\n",
    "\n",
    "######################################[[[[[[[[[    DataLoaders    ]]]]]]]]]]]#############################################\n",
    "\n",
    "# training dataLoader\n",
    "train_loader=DataLoader(\n",
    "    train_set,\n",
    "    batch_size= batch_size, shuffle=True, num_workers = num_workers , \n",
    ")\n",
    "\n",
    "# testing DataLoader\n",
    "val_loader=DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size, shuffle= False, )\n",
    "\n",
    "\n",
    "# testing DataLoader\n",
    "test_loader=DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size, shuffle= False, )\n",
    "\n",
    "\n",
    "\n",
    "#calculating the size of training and testing images\n",
    "#train_count=len(glob.glob(train_root+'/**/*.jpg'))\n",
    "#test_count=len(glob.glob(test_root+'/**/*.jpg'))\n",
    "\n",
    "train_count = len(train_set)\n",
    "val_count = len(val_set)\n",
    "test_count = len(test_set)\n",
    "\n",
    "\n",
    "# Classes\n",
    "root=pathlib.Path(train_root)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "\n",
    "\n",
    "# Print datasets size\n",
    "print(f'Training images are:     {train_count}')\n",
    "print(f'Validation images are:   {val_count}')\n",
    "print(f'Testing images are:      {test_count}', '\\n')\n",
    "print('Classes are: ',classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cea3e6-0026-43c1-8802-049bea815cd5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5480bf17-421a-40d5-8303-4c1073b2ba3c",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    " <center> Step 03: Model Architecture </center>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa60bbe-52a7-4698-8f5b-962e8427dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Network Architecture\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=6):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #Output size after convolution filter\n",
    "        #((w-f+2P)/s) +1\n",
    "        \n",
    "        #Input shape= (batch_size,3,150,150)\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (batch_size,12,150,150)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        #Shape= (batch_size,12,150,150)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #Shape= (batch_size,12,150,150)\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size be factor 2\n",
    "        #Shape= (batch_size,12,75,75)\n",
    "        \n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (batch_size,20,75,75)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Shape= (batch_size,20,75,75)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (batch_size,32,75,75)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        #Shape= (batch_size,32,75,75)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #Shape= (batch_size,32,75,75)\n",
    "        \n",
    "        self.fc1=nn.Linear(in_features=75 * 75 * 32,out_features=120)\n",
    "        self.fc2=nn.Linear(in_features=120,out_features=num_classes)\n",
    "        \n",
    "        \n",
    "        \n",
    "#Feed forwad function\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "            \n",
    "            \n",
    "#Above output will be in matrix form, with shape (batch_size,32,75,75)\n",
    "            \n",
    "        output=output.view(-1,32*75*75)\n",
    "            \n",
    "            \n",
    "        output=self.fc1(output)\n",
    "        output=self.fc2(output)\n",
    "            \n",
    "        return output\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c01968-956b-46dd-b2eb-659c4c3e9667",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=6).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3576bd7-028b-4dc9-a45d-516c6ddc28f0",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<center> Step 04: Defining Loss and Optimizer</center>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3221eae-2394-4d29-adfa-1ac4f4544997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optmizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.001)\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb30f3-fc39-4429-bcb5-067c6d31f1eb",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<center> Step 05: Model Training </center>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df080f-508d-41ab-bd6a-ea516dc5bbd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's train the model and evaluate it. Save the best model\n",
    "\n",
    "train_log =[]\n",
    "val_log = []\n",
    "best_accuracy=0.0\n",
    "\n",
    "# iterate over the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "#Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "\n",
    "\n",
    "# load and iterate over training batches    \n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "# backpropagation            \n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#calculate the metrics        \n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "# final train accuracy and loss for the given epoch        \n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "# Evaluation on validation dataset\n",
    "    with torch.no_grad():    \n",
    "        model.eval()\n",
    "        val_accuracy=0.0\n",
    "        val_loss = 0.0\n",
    "        \n",
    "# load and iterate over all batches\n",
    "        for i, (images,labels) in enumerate(val_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                images=Variable(images.cuda())\n",
    "                labels=Variable(labels.cuda())\n",
    "                \n",
    "#calculate the metrics                \n",
    "            outputs=model(images)\n",
    "            loss=loss_function(outputs,labels)\n",
    "            _,prediction=torch.max(outputs.data,1)\n",
    "            val_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "            val_loss+= loss.cpu().data*images.size(0)\n",
    "            \n",
    "#calculate validation accuracy and loss for this epoch       \n",
    "        val_accuracy=val_accuracy/val_count\n",
    "        val_loss=val_loss/val_count\n",
    "        \n",
    "# save the training and validation loss for this epoch\n",
    "    train_log.append(train_loss.item())\n",
    "    val_log.append(val_loss.item())\n",
    "\n",
    "# print epoch results\n",
    "    print('Epoch:'+str(epoch)+' Train Loss:'+str(train_loss.item())+' Val Loss:'+str(val_loss.item())+' Train Accuracy:'+str(train_accuracy)+' Val Accuracy:'+str(val_accuracy))\n",
    "    \n",
    "#Save the best model\n",
    "    if val_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "        best_accuracy=val_accuracy\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917b935a-e79d-4070-abbf-e79f5eeb90dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save misclassified images to the directory while testing\n",
    "\n",
    "def save_misclassified_images(images, predictions, labels, classes, save_dir):\n",
    "    misclassified_indices = (predictions != labels).nonzero()  # Get the tuple of tensors\n",
    "    if misclassified_indices:  # Check if any misclassified indices exist\n",
    "        misclassified_indices = misclassified_indices[0]  # Extract the first tensor if present\n",
    "        for index in misclassified_indices:\n",
    "            image = images[index]\n",
    "\n",
    "            true_label = classes[labels[index].item()]  # Access the scalar value using .item()\n",
    "            predicted_label = classes[predictions[index].item()]\n",
    "            #true_label = classes[labels[index]]\n",
    "           # predicted_label = classes[predictions[index]]\n",
    "            filename = f\"misclassified_{i}_{true_label}_{predicted_label}.jpg\"\n",
    "    \n",
    "            # Normalize if needed\n",
    "            if torch.is_tensor(image):\n",
    "                image = image.permute(1, 2, 0).cpu().numpy()\n",
    "            #plt.imsave(os.path.join(save_dir, filename), image)\n",
    "\n",
    "            plt.imshow(image)  # Displays the image\n",
    "            plt.savefig(os.path.join(save_dir, filename))  # Saves the displayed image\n",
    "            plt.close()  # Closes the figure to avoid memory leaks\n",
    "\n",
    "def show_saved_images(save_dir, num_images=5):\n",
    "    saved_images = os.listdir(save_dir)[:num_images]\n",
    "    for filename in saved_images:\n",
    "        image = plt.imread(os.path.join(save_dir, filename))\n",
    "        plt.imshow(image)\n",
    "        plt.title(filename)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988c78b7-b207-426f-9049-b7ca5e111dff",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<center> Step 06: Model Testing </center>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70df350-6050-4a52-b244-d622572b7291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#testing phase\n",
    "\n",
    "# defining directory for our misclassified samples\n",
    "save_dir = \"./data1/Intel_dataset/misclassified_set\"\n",
    "\n",
    "model.load_state_dict(torch.load('best_checkpoint.model'))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "incorrect_examples = []\n",
    "misclassified_idx = []\n",
    "\n",
    "# iterate over test data\n",
    "for i, (images,labels) in enumerate(test_loader):\n",
    "\n",
    "# convert to cuda tensors\n",
    "    if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "        \n",
    "# No gradients required during testing\n",
    "    with torch.no_grad():\n",
    "        outputs=model(images) # Feed Network\n",
    "        outputs = (torch.max(torch.exp(outputs), 1)[1]).data.cpu().numpy()\n",
    "        y_pred.extend(outputs) # Save Prediction\n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels) # Save Truth\n",
    "        save_misclassified_images(images, outputs, labels, classes, save_dir)\n",
    "\n",
    "# Later, to view the saved images:\n",
    "show_saved_images(save_dir)\n",
    "    \n",
    "    #precision_metric.update(y_pred, y_true)\n",
    "    #recall_metric.update(y_pred, y_true)\n",
    "    #f1_metric.update(y_pred, y_true)\n",
    "\n",
    "# constant for classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbadc82-9114-44e5-af73-f4e613f1302e",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<center> Step 07: Results Evaluation and Visualization</center>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ee7d5-80ae-45f9-bbc6-48378e79b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_true, y_pred, average = None)\n",
    "recall = recall_score(y_true, y_pred, average = None)\n",
    "f1 = f1_score(y_true, y_pred, average = None)\n",
    "\n",
    "print('Classes:    ', '    '.join('%s' % classes[j] for j in range(6)))\n",
    "#print('  ', Class[i] for i,n in enumerate(Classes))\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:   \", recall)\n",
    "print(\"F1-score: \", f1)\n",
    "\n",
    "print(\" Average Precision:\", sum(precision)/6)\n",
    "print(\"Average Recall:   \", sum(recall)/6)\n",
    "print(\"Average F1-score: \", sum(f1)/6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ea331e-6aa8-4066-afce-6944c7034137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sns.heatmap(df_cm, annot=True)\n",
    "#plt.savefig('output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a4d013-ebb9-4885-a0fb-a4f15ed35b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(train_log, label=\"train_loss\")\n",
    "plt.plot(val_log, label=\"val_loss\")\n",
    "#plt.plot(H[\"train_acc\"], label=\"train_acc\")\n",
    "#plt.plot(H[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig('train_val_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3196f0d-7208-42f2-ad93-602b23ab8f1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'splitfolders'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msplitfolders\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'splitfolders'"
     ]
    }
   ],
   "source": [
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11803ee4-d508-4914-b03c-dcaceaedc959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
